{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import string\n",
    "# search the text for a word\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.text import Text\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "\n",
    "#To plot the graphs\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "#library used to count the frequency of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#To create the sentiment analysis model, tokenization and lemmatization\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import word_tokenize\n",
    "import nltk.data\n",
    "#nltk.download('vader_lexicon')\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = pd.read_csv('../../files/csv/lyricsenhanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Kollegah &amp; Farid Bang</td>\n",
       "      <td>One Night Stand</td>\n",
       "      <td>2018</td>\n",
       "      <td>Fass' dich an, frag', „Ist die Brust da echt?“...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Bausa</td>\n",
       "      <td>FML</td>\n",
       "      <td>2018</td>\n",
       "      <td>Ouh-oh-oh-ouh-ouh\\nBaby, ich weiß, was du will...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Jazn</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jajajaja\\nOhh, kippe Bombay\\nJaja, jaja, ohh\\n...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Tom Walker</td>\n",
       "      <td>Leave A Light On</td>\n",
       "      <td>2018</td>\n",
       "      <td>The second someone mentioned you were all alon...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>G-Eazy feat. A$AP Rocky &amp; Cardi B</td>\n",
       "      <td>No Limit</td>\n",
       "      <td>2018</td>\n",
       "      <td>If I hit it one time, I'ma pipe her\\nIf I hit ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>1863</td>\n",
       "      <td>1864</td>\n",
       "      <td>Reezy feat. Nimo</td>\n",
       "      <td>Trance</td>\n",
       "      <td>2020</td>\n",
       "      <td>Ich wart' seit Tagen auf dich, bis du wieder k...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>1864</td>\n",
       "      <td>1865</td>\n",
       "      <td>Loredana</td>\n",
       "      <td>Gangster</td>\n",
       "      <td>2020</td>\n",
       "      <td>Miksu\\nMacloud\\n\\nDu sagst, du bist ein Gangst...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>1865</td>\n",
       "      <td>1866</td>\n",
       "      <td>Lil Nas X</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>2020</td>\n",
       "      <td>T-T-Tay Keith, Took it to ten (Hey)\\n\\nAyy, it...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>1866</td>\n",
       "      <td>1867</td>\n",
       "      <td>Studio Killers</td>\n",
       "      <td>Jenny</td>\n",
       "      <td>2020</td>\n",
       "      <td>Jenny, darling, you're my best friend\\nBut the...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>1867</td>\n",
       "      <td>1868</td>\n",
       "      <td>Michael Bublé</td>\n",
       "      <td>White Christmas</td>\n",
       "      <td>2020</td>\n",
       "      <td>I'm dreaming of a white Christmas\\nJust like t...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1868 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    id                             artist             title  \\\n",
       "0              0     1              Kollegah & Farid Bang   One Night Stand   \n",
       "1              1     2                              Bausa               FML   \n",
       "2              2     3                               Jazn            Bombay   \n",
       "3              3     4                         Tom Walker  Leave A Light On   \n",
       "4              4     5  G-Eazy feat. A$AP Rocky & Cardi B          No Limit   \n",
       "...          ...   ...                                ...               ...   \n",
       "1863        1863  1864                   Reezy feat. Nimo            Trance   \n",
       "1864        1864  1865                           Loredana          Gangster   \n",
       "1865        1865  1866                          Lil Nas X           Holiday   \n",
       "1866        1866  1867                     Studio Killers             Jenny   \n",
       "1867        1867  1868                      Michael Bublé   White Christmas   \n",
       "\n",
       "      year                                             lyrics lang  \n",
       "0     2018  Fass' dich an, frag', „Ist die Brust da echt?“...   de  \n",
       "1     2018  Ouh-oh-oh-ouh-ouh\\nBaby, ich weiß, was du will...   de  \n",
       "2     2018  Jajajaja\\nOhh, kippe Bombay\\nJaja, jaja, ohh\\n...   de  \n",
       "3     2018  The second someone mentioned you were all alon...   en  \n",
       "4     2018  If I hit it one time, I'ma pipe her\\nIf I hit ...   en  \n",
       "...    ...                                                ...  ...  \n",
       "1863  2020  Ich wart' seit Tagen auf dich, bis du wieder k...   de  \n",
       "1864  2020  Miksu\\nMacloud\\n\\nDu sagst, du bist ein Gangst...   de  \n",
       "1865  2020  T-T-Tay Keith, Took it to ten (Hey)\\n\\nAyy, it...   en  \n",
       "1866  2020  Jenny, darling, you're my best friend\\nBut the...   en  \n",
       "1867  2020  I'm dreaming of a white Christmas\\nJust like t...   en  \n",
       "\n",
       "[1868 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = lyrics.drop(['Unnamed: 0'], axis=1)\n",
    "lyrics = lyrics.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "artist    0\n",
       "title     0\n",
       "year      0\n",
       "lyrics    0\n",
       "lang      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenlist = []\n",
    "for token in lyrics['lyrics']:\n",
    "    t = word_tokenize(token)\n",
    "    tokenlist.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lyrics['token'] = tokenlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some cleaning - create table of punctuation from module string \n",
    "\n",
    "punctable = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "\n",
    "#split out the words around whitespace, full stops etc \n",
    "\n",
    "wordlist = []\n",
    "\n",
    "for lyrical in lyrics['lyrics']:\n",
    "    words = lyrical.split()\n",
    "\n",
    "    #remove punctuation \n",
    "    strippedwords = [w.translate(punctable) for w in words]\n",
    "\n",
    "    #remove quotation marks\n",
    "    quotelesswords = [w.replace('„', '').replace('“', '') for w in strippedwords]\n",
    "    \n",
    "    #make lower case \n",
    "    lowerwords = [word.lower() for word in quotelesswords]\n",
    "    wordlist.append(lowerwords)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fass',\n",
       " 'dich',\n",
       " 'an',\n",
       " 'frag',\n",
       " 'ist',\n",
       " 'die',\n",
       " 'brust',\n",
       " 'da',\n",
       " 'echt',\n",
       " 'ich',\n",
       " 'tanz',\n",
       " 'dich',\n",
       " 'an',\n",
       " 'und',\n",
       " 'du',\n",
       " 'schubst',\n",
       " 'mich',\n",
       " 'weg',\n",
       " 'bin',\n",
       " 'der',\n",
       " 'grund',\n",
       " 'dass',\n",
       " 'du',\n",
       " 'den',\n",
       " 'club',\n",
       " 'verlässt',\n",
       " 'nah',\n",
       " 'das',\n",
       " 'zeigt',\n",
       " 'mir',\n",
       " 'du',\n",
       " 'hast',\n",
       " 'lust',\n",
       " 'auf',\n",
       " 'sex',\n",
       " 'vip',\n",
       " 'wie',\n",
       " 'dieser',\n",
       " 'emory',\n",
       " 'mit',\n",
       " 'menowin',\n",
       " 'und',\n",
       " 'refugees',\n",
       " 'yallah',\n",
       " 'keine',\n",
       " 'bosstrafo',\n",
       " 'mit',\n",
       " 'lowcarbdiät',\n",
       " 'ich',\n",
       " 'verliere',\n",
       " 'gewicht',\n",
       " 'durch',\n",
       " 'kokain',\n",
       " 'nehmn',\n",
       " 'birra',\n",
       " 'bitches',\n",
       " 'kommen',\n",
       " 'mit',\n",
       " 'und',\n",
       " 'ich',\n",
       " 'führ',\n",
       " 'sie',\n",
       " 'hinaus',\n",
       " 'sie',\n",
       " 'vertraun',\n",
       " 'mir',\n",
       " 'denn',\n",
       " 'ich',\n",
       " 'seh',\n",
       " 'wie',\n",
       " 'der',\n",
       " 'türsteher',\n",
       " 'aus',\n",
       " 'hajde',\n",
       " 'heute',\n",
       " 'wird',\n",
       " 'mein',\n",
       " 'schwanz',\n",
       " 'gesuckt',\n",
       " 'kein',\n",
       " 'onenightstand',\n",
       " 'nein',\n",
       " 'ich',\n",
       " 'bleib',\n",
       " 'nicht',\n",
       " 'die',\n",
       " 'ganze',\n",
       " 'nacht',\n",
       " 'baby',\n",
       " 'trink',\n",
       " 'den',\n",
       " 'schluck',\n",
       " 'auf',\n",
       " 'ex',\n",
       " 'denn',\n",
       " 'ich',\n",
       " 'habe',\n",
       " 'lust',\n",
       " 'auf',\n",
       " 'sex',\n",
       " 'ich',\n",
       " 'hab',\n",
       " 'für',\n",
       " 'den',\n",
       " 'puff',\n",
       " 'kaum',\n",
       " 'cash',\n",
       " 'doch',\n",
       " 'baby',\n",
       " 'ich',\n",
       " 'hab',\n",
       " 'lust',\n",
       " 'auf',\n",
       " 'sex',\n",
       " 'ich',\n",
       " 'folge',\n",
       " 'deinem',\n",
       " 'instagram',\n",
       " 'jetzt',\n",
       " 'sind',\n",
       " 'wir',\n",
       " 'onlinefriends',\n",
       " 'also',\n",
       " 'gib',\n",
       " 'mir',\n",
       " 'diesen',\n",
       " 'onenightstand',\n",
       " 'ich',\n",
       " 'krieg',\n",
       " 'einn',\n",
       " 'steifen',\n",
       " 'während',\n",
       " 'du',\n",
       " 'im',\n",
       " 'spotlight',\n",
       " 'danct',\n",
       " 'baby',\n",
       " 'gib',\n",
       " 'mir',\n",
       " 'diesen',\n",
       " 'onenightstand',\n",
       " 'keiner',\n",
       " 'von',\n",
       " 'uns',\n",
       " 'zwei',\n",
       " 'der',\n",
       " 'hier',\n",
       " 'an',\n",
       " 'hochzeit',\n",
       " 'denkt',\n",
       " 'also',\n",
       " 'gib',\n",
       " 'mir',\n",
       " 'diesen',\n",
       " 'onenightstand',\n",
       " 'vielleicht',\n",
       " 'sehn',\n",
       " 'wir',\n",
       " 'uns',\n",
       " 'auch',\n",
       " 'nie',\n",
       " 'wieder',\n",
       " 'mehr',\n",
       " 'also',\n",
       " 'gib',\n",
       " 'mir',\n",
       " 'diesen',\n",
       " 'onenightstand',\n",
       " 'du',\n",
       " 'verdrehst',\n",
       " 'die',\n",
       " 'augen',\n",
       " 'wenn',\n",
       " 'ich',\n",
       " 'mit',\n",
       " 'den',\n",
       " 'muskeln',\n",
       " 'flex',\n",
       " 'gib',\n",
       " 'mal',\n",
       " 'nummer',\n",
       " 'und',\n",
       " 'du',\n",
       " 'sagst',\n",
       " 'mein',\n",
       " 'bus',\n",
       " 'fährt',\n",
       " 'jetzt',\n",
       " 'du',\n",
       " 'rufst',\n",
       " 'die',\n",
       " 'cops',\n",
       " 'denn',\n",
       " 'ich',\n",
       " 'box',\n",
       " 'deinn',\n",
       " 'freund',\n",
       " 'die',\n",
       " 'schwuchtel',\n",
       " 'weg',\n",
       " 'denn',\n",
       " 'baby',\n",
       " 'ich',\n",
       " 'hab',\n",
       " 'lust',\n",
       " 'auf',\n",
       " 'sex',\n",
       " 'ja',\n",
       " 'wir',\n",
       " 'habn',\n",
       " 'uns',\n",
       " 'für',\n",
       " 'die',\n",
       " 'disco',\n",
       " 'breit',\n",
       " 'gepumpt',\n",
       " 'ja',\n",
       " 'haun',\n",
       " 'die',\n",
       " 'türsteher',\n",
       " 'am',\n",
       " 'eingang',\n",
       " 'wie',\n",
       " 'paar',\n",
       " 'kickboxfighter',\n",
       " 'um',\n",
       " 'ja',\n",
       " 'häng',\n",
       " 'mit',\n",
       " 'emory',\n",
       " 'im',\n",
       " 'vipbereich',\n",
       " 'herum',\n",
       " 'sehn',\n",
       " 'uns',\n",
       " 'nach',\n",
       " 'fickbereiten',\n",
       " 'spitzen',\n",
       " 'weibern',\n",
       " 'in',\n",
       " 'mit',\n",
       " 'glitzersteinn',\n",
       " 'geschmückten',\n",
       " 'minikleidern',\n",
       " 'um',\n",
       " 'also',\n",
       " 'komm',\n",
       " 'an',\n",
       " 'die',\n",
       " 'bar',\n",
       " 'da',\n",
       " 'geht',\n",
       " 'die',\n",
       " 'runde',\n",
       " 'auf',\n",
       " 'mich',\n",
       " 'yeah',\n",
       " 'als',\n",
       " 'ob',\n",
       " 'ich',\n",
       " 'ne',\n",
       " 'pummlige',\n",
       " 'fick',\n",
       " 'heute',\n",
       " 'wird',\n",
       " 'der',\n",
       " 'schwanz',\n",
       " 'gesuckt',\n",
       " 'kein',\n",
       " 'onenightstand',\n",
       " 'nein',\n",
       " 'ich',\n",
       " 'bleib',\n",
       " 'nicht',\n",
       " 'die',\n",
       " 'ganze',\n",
       " 'nacht',\n",
       " 'baby',\n",
       " 'trink',\n",
       " 'den',\n",
       " 'schluck',\n",
       " 'auf',\n",
       " 'ex',\n",
       " 'denn',\n",
       " 'ich',\n",
       " 'habe',\n",
       " 'lust',\n",
       " 'auf',\n",
       " 'sex',\n",
       " 'ich',\n",
       " 'hab',\n",
       " 'für',\n",
       " 'den',\n",
       " 'puff',\n",
       " 'kaum',\n",
       " 'cash',\n",
       " 'doch',\n",
       " 'baby',\n",
       " 'ich',\n",
       " 'hab',\n",
       " 'lust',\n",
       " 'auf',\n",
       " 'sex',\n",
       " 'ich',\n",
       " 'folge',\n",
       " 'deinem',\n",
       " 'instagram',\n",
       " 'jetzt',\n",
       " 'sind',\n",
       " 'wir',\n",
       " 'onlinefriends',\n",
       " 'also',\n",
       " 'gib',\n",
       " 'mir',\n",
       " 'diesen',\n",
       " 'onenightstand',\n",
       " 'ich',\n",
       " 'krieg',\n",
       " 'einn',\n",
       " 'steifen',\n",
       " 'während',\n",
       " 'du',\n",
       " 'im',\n",
       " 'spotlight',\n",
       " 'danct',\n",
       " 'baby',\n",
       " 'gib',\n",
       " 'mir',\n",
       " 'diesen',\n",
       " 'onenightstand',\n",
       " 'keiner',\n",
       " 'von',\n",
       " 'uns',\n",
       " 'zwei',\n",
       " 'der',\n",
       " 'hier',\n",
       " 'an',\n",
       " 'hochzeit',\n",
       " 'denkt',\n",
       " 'also',\n",
       " 'gib',\n",
       " 'mir',\n",
       " 'diesen',\n",
       " 'onenightstand',\n",
       " 'vielleicht',\n",
       " 'sehn',\n",
       " 'wir',\n",
       " 'uns',\n",
       " 'auch',\n",
       " 'nie',\n",
       " 'wieder',\n",
       " 'mehr',\n",
       " 'also',\n",
       " 'gib',\n",
       " 'mir',\n",
       " 'diesen',\n",
       " 'onenightstand',\n",
       " 'onenightstand',\n",
       " 'onenightstand',\n",
       " 'onenightstand',\n",
       " 'onenightstand',\n",
       " 'baby',\n",
       " 'trink',\n",
       " 'den',\n",
       " 'schluck',\n",
       " 'auf',\n",
       " 'ex',\n",
       " 'denn',\n",
       " 'ich',\n",
       " 'habe',\n",
       " 'lust',\n",
       " 'auf',\n",
       " 'sex',\n",
       " 'ich',\n",
       " 'hab',\n",
       " 'für',\n",
       " 'den',\n",
       " 'puff',\n",
       " 'kaum',\n",
       " 'cash',\n",
       " 'doch',\n",
       " 'baby',\n",
       " 'ich',\n",
       " 'hab',\n",
       " 'lust',\n",
       " 'auf',\n",
       " 'sex',\n",
       " 'ich',\n",
       " 'folge',\n",
       " 'deinem',\n",
       " 'instagram',\n",
       " 'jetzt',\n",
       " 'sind',\n",
       " 'wir',\n",
       " 'onlinefriends',\n",
       " 'also',\n",
       " 'gib',\n",
       " 'mir',\n",
       " 'diesen',\n",
       " 'onenightstand',\n",
       " 'ich',\n",
       " 'krieg',\n",
       " 'einn',\n",
       " 'steifen',\n",
       " 'während',\n",
       " 'du',\n",
       " 'im',\n",
       " 'spotlight',\n",
       " 'danct',\n",
       " 'baby',\n",
       " 'gib',\n",
       " 'mir',\n",
       " 'diesen',\n",
       " 'onenightstand',\n",
       " 'keiner',\n",
       " 'von',\n",
       " 'uns',\n",
       " 'zwei',\n",
       " 'der',\n",
       " 'hier',\n",
       " 'an',\n",
       " 'hochzeit',\n",
       " 'denkt',\n",
       " 'also',\n",
       " 'gib',\n",
       " 'mir',\n",
       " 'diesen',\n",
       " 'onenightstand',\n",
       " 'vielleicht',\n",
       " 'sehn',\n",
       " 'wir',\n",
       " 'uns',\n",
       " 'auch',\n",
       " 'nie',\n",
       " 'wieder',\n",
       " 'mehr',\n",
       " 'also',\n",
       " 'gib',\n",
       " 'mir',\n",
       " 'diesen',\n",
       " 'onenightstand',\n",
       " 'onenightstand']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics['words'] = wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>lang</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Kollegah &amp; Farid Bang</td>\n",
       "      <td>One Night Stand</td>\n",
       "      <td>2018</td>\n",
       "      <td>Fass' dich an, frag', „Ist die Brust da echt?“...</td>\n",
       "      <td>de</td>\n",
       "      <td>[fass, dich, an, frag, ist, die, brust, da, ec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bausa</td>\n",
       "      <td>FML</td>\n",
       "      <td>2018</td>\n",
       "      <td>Ouh-oh-oh-ouh-ouh\\nBaby, ich weiß, was du will...</td>\n",
       "      <td>de</td>\n",
       "      <td>[ouhohohouhouh, baby, ich, weiß, was, du, will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Jazn</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jajajaja\\nOhh, kippe Bombay\\nJaja, jaja, ohh\\n...</td>\n",
       "      <td>de</td>\n",
       "      <td>[jajajaja, ohh, kippe, bombay, jaja, jaja, ohh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Tom Walker</td>\n",
       "      <td>Leave A Light On</td>\n",
       "      <td>2018</td>\n",
       "      <td>The second someone mentioned you were all alon...</td>\n",
       "      <td>en</td>\n",
       "      <td>[the, second, someone, mentioned, you, were, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>G-Eazy feat. A$AP Rocky &amp; Cardi B</td>\n",
       "      <td>No Limit</td>\n",
       "      <td>2018</td>\n",
       "      <td>If I hit it one time, I'ma pipe her\\nIf I hit ...</td>\n",
       "      <td>en</td>\n",
       "      <td>[if, i, hit, it, one, time, ima, pipe, her, if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>1864</td>\n",
       "      <td>Reezy feat. Nimo</td>\n",
       "      <td>Trance</td>\n",
       "      <td>2020</td>\n",
       "      <td>Ich wart' seit Tagen auf dich, bis du wieder k...</td>\n",
       "      <td>de</td>\n",
       "      <td>[ich, wart, seit, tagen, auf, dich, bis, du, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>1865</td>\n",
       "      <td>Loredana</td>\n",
       "      <td>Gangster</td>\n",
       "      <td>2020</td>\n",
       "      <td>Miksu\\nMacloud\\n\\nDu sagst, du bist ein Gangst...</td>\n",
       "      <td>de</td>\n",
       "      <td>[miksu, macloud, du, sagst, du, bist, ein, gan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>1866</td>\n",
       "      <td>Lil Nas X</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>2020</td>\n",
       "      <td>T-T-Tay Keith, Took it to ten (Hey)\\n\\nAyy, it...</td>\n",
       "      <td>en</td>\n",
       "      <td>[tttay, keith, took, it, to, ten, hey, ayy, it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>1867</td>\n",
       "      <td>Studio Killers</td>\n",
       "      <td>Jenny</td>\n",
       "      <td>2020</td>\n",
       "      <td>Jenny, darling, you're my best friend\\nBut the...</td>\n",
       "      <td>en</td>\n",
       "      <td>[jenny, darling, youre, my, best, friend, but,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>1868</td>\n",
       "      <td>Michael Bublé</td>\n",
       "      <td>White Christmas</td>\n",
       "      <td>2020</td>\n",
       "      <td>I'm dreaming of a white Christmas\\nJust like t...</td>\n",
       "      <td>en</td>\n",
       "      <td>[im, dreaming, of, a, white, christmas, just, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1835 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                             artist             title  year  \\\n",
       "0        1              Kollegah & Farid Bang   One Night Stand  2018   \n",
       "1        2                              Bausa               FML  2018   \n",
       "2        3                               Jazn            Bombay  2018   \n",
       "3        4                         Tom Walker  Leave A Light On  2018   \n",
       "4        5  G-Eazy feat. A$AP Rocky & Cardi B          No Limit  2018   \n",
       "...    ...                                ...               ...   ...   \n",
       "1863  1864                   Reezy feat. Nimo            Trance  2020   \n",
       "1864  1865                           Loredana          Gangster  2020   \n",
       "1865  1866                          Lil Nas X           Holiday  2020   \n",
       "1866  1867                     Studio Killers             Jenny  2020   \n",
       "1867  1868                      Michael Bublé   White Christmas  2020   \n",
       "\n",
       "                                                 lyrics lang  \\\n",
       "0     Fass' dich an, frag', „Ist die Brust da echt?“...   de   \n",
       "1     Ouh-oh-oh-ouh-ouh\\nBaby, ich weiß, was du will...   de   \n",
       "2     Jajajaja\\nOhh, kippe Bombay\\nJaja, jaja, ohh\\n...   de   \n",
       "3     The second someone mentioned you were all alon...   en   \n",
       "4     If I hit it one time, I'ma pipe her\\nIf I hit ...   en   \n",
       "...                                                 ...  ...   \n",
       "1863  Ich wart' seit Tagen auf dich, bis du wieder k...   de   \n",
       "1864  Miksu\\nMacloud\\n\\nDu sagst, du bist ein Gangst...   de   \n",
       "1865  T-T-Tay Keith, Took it to ten (Hey)\\n\\nAyy, it...   en   \n",
       "1866  Jenny, darling, you're my best friend\\nBut the...   en   \n",
       "1867  I'm dreaming of a white Christmas\\nJust like t...   en   \n",
       "\n",
       "                                                  words  \n",
       "0     [fass, dich, an, frag, ist, die, brust, da, ec...  \n",
       "1     [ouhohohouhouh, baby, ich, weiß, was, du, will...  \n",
       "2     [jajajaja, ohh, kippe, bombay, jaja, jaja, ohh...  \n",
       "3     [the, second, someone, mentioned, you, were, a...  \n",
       "4     [if, i, hit, it, one, time, ima, pipe, her, if...  \n",
       "...                                                 ...  \n",
       "1863  [ich, wart, seit, tagen, auf, dich, bis, du, w...  \n",
       "1864  [miksu, macloud, du, sagst, du, bist, ein, gan...  \n",
       "1865  [tttay, keith, took, it, to, ten, hey, ayy, it...  \n",
       "1866  [jenny, darling, youre, my, best, friend, but,...  \n",
       "1867  [im, dreaming, of, a, white, christmas, just, ...  \n",
       "\n",
       "[1835 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ich', 25),\n",
       " ('onenightstand', 19),\n",
       " ('mir', 14),\n",
       " ('gib', 13),\n",
       " ('auf', 12),\n",
       " ('diesen', 12),\n",
       " ('die', 10),\n",
       " ('baby', 10),\n",
       " ('also', 10),\n",
       " ('du', 9),\n",
       " ('den', 8),\n",
       " ('lust', 8),\n",
       " ('sex', 8),\n",
       " ('uns', 8),\n",
       " ('hab', 7),\n",
       " ('wir', 7),\n",
       " ('an', 6),\n",
       " ('der', 6),\n",
       " ('mit', 6),\n",
       " ('denn', 6),\n",
       " ('und', 4),\n",
       " ('für', 4),\n",
       " ('jetzt', 4),\n",
       " ('im', 4),\n",
       " ('sehn', 4),\n",
       " ('wie', 3),\n",
       " ('trink', 3),\n",
       " ('schluck', 3),\n",
       " ('ex', 3),\n",
       " ('habe', 3),\n",
       " ('puff', 3),\n",
       " ('kaum', 3),\n",
       " ('cash', 3),\n",
       " ('doch', 3),\n",
       " ('folge', 3),\n",
       " ('deinem', 3),\n",
       " ('instagram', 3),\n",
       " ('sind', 3),\n",
       " ('onlinefriends', 3),\n",
       " ('krieg', 3),\n",
       " ('einn', 3),\n",
       " ('steifen', 3),\n",
       " ('während', 3),\n",
       " ('spotlight', 3),\n",
       " ('danct', 3),\n",
       " ('keiner', 3),\n",
       " ('von', 3),\n",
       " ('zwei', 3),\n",
       " ('hier', 3),\n",
       " ('hochzeit', 3)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count freq of words in the text \n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "fdistlyrics1 = FreqDist(lyrics['words'][0])\n",
    "fdistlyrics1.most_common(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1835/1835 [14:08<00:00,  2.16it/s]\n"
     ]
    }
   ],
   "source": [
    "wordlist = []\n",
    "\n",
    "for i in tqdm(range(len(lyrics['words']))):\n",
    "    try:\n",
    "        sublist = [word for word in lyrics['words'][i] if not word in stopwords.words('english')]\n",
    "        sublist = [word for word in sublist if not word in stopwords.words('german')]\n",
    "        sublist = [word for word in sublist if not word in stopwords.words('french')]\n",
    "        sublist = [word for word in sublist if not word in stopwords.words('spanish')]\n",
    "        sublist = [word for word in sublist if not word in stopwords.words('italian')]\n",
    "        sublist = [word for word in sublist if not word in stopwords.words('turkish')]\n",
    "        wordlist.append(sublist)\n",
    "    except:\n",
    "        wordlist.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics['words'] = wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>lang</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Kollegah &amp; Farid Bang</td>\n",
       "      <td>One Night Stand</td>\n",
       "      <td>2018</td>\n",
       "      <td>Fass' dich an, frag', „Ist die Brust da echt?“...</td>\n",
       "      <td>de</td>\n",
       "      <td>[fass, frag, brust, echt, tanz, schubst, grund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bausa</td>\n",
       "      <td>FML</td>\n",
       "      <td>2018</td>\n",
       "      <td>Ouh-oh-oh-ouh-ouh\\nBaby, ich weiß, was du will...</td>\n",
       "      <td>de</td>\n",
       "      <td>[ouhohohouhouh, baby, weiß, willst, weißt, kom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Jazn</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jajajaja\\nOhh, kippe Bombay\\nJaja, jaja, ohh\\n...</td>\n",
       "      <td>de</td>\n",
       "      <td>[jajajaja, ohh, kippe, bombay, jaja, jaja, ohh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Tom Walker</td>\n",
       "      <td>Leave A Light On</td>\n",
       "      <td>2018</td>\n",
       "      <td>The second someone mentioned you were all alon...</td>\n",
       "      <td>en</td>\n",
       "      <td>[second, someone, mentioned, alone, could, fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>G-Eazy feat. A$AP Rocky &amp; Cardi B</td>\n",
       "      <td>No Limit</td>\n",
       "      <td>2018</td>\n",
       "      <td>If I hit it one time, I'ma pipe her\\nIf I hit ...</td>\n",
       "      <td>en</td>\n",
       "      <td>[hit, one, time, ima, pipe, hit, two, times, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>1864</td>\n",
       "      <td>Reezy feat. Nimo</td>\n",
       "      <td>Trance</td>\n",
       "      <td>2020</td>\n",
       "      <td>Ich wart' seit Tagen auf dich, bis du wieder k...</td>\n",
       "      <td>de</td>\n",
       "      <td>[yeah, hes, heaven, oh, yeah, youre, lying, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>1865</td>\n",
       "      <td>Loredana</td>\n",
       "      <td>Gangster</td>\n",
       "      <td>2020</td>\n",
       "      <td>Miksu\\nMacloud\\n\\nDu sagst, du bist ein Gangst...</td>\n",
       "      <td>de</td>\n",
       "      <td>[stahlharter, gladiator, baller, paar, bars, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>1866</td>\n",
       "      <td>Lil Nas X</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>2020</td>\n",
       "      <td>T-T-Tay Keith, Took it to ten (Hey)\\n\\nAyy, it...</td>\n",
       "      <td>en</td>\n",
       "      <td>[entstanden, unendlich, langer, zeit, wunder, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>1867</td>\n",
       "      <td>Studio Killers</td>\n",
       "      <td>Jenny</td>\n",
       "      <td>2020</td>\n",
       "      <td>Jenny, darling, you're my best friend\\nBut the...</td>\n",
       "      <td>en</td>\n",
       "      <td>[heavy, sso, shit, loyalty, royalty, yall, nig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>1868</td>\n",
       "      <td>Michael Bublé</td>\n",
       "      <td>White Christmas</td>\n",
       "      <td>2020</td>\n",
       "      <td>I'm dreaming of a white Christmas\\nJust like t...</td>\n",
       "      <td>en</td>\n",
       "      <td>[yeah, ah, kennst, einn, traum, hast, draußen,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1835 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                             artist             title  year  \\\n",
       "0        1              Kollegah & Farid Bang   One Night Stand  2018   \n",
       "1        2                              Bausa               FML  2018   \n",
       "2        3                               Jazn            Bombay  2018   \n",
       "3        4                         Tom Walker  Leave A Light On  2018   \n",
       "4        5  G-Eazy feat. A$AP Rocky & Cardi B          No Limit  2018   \n",
       "...    ...                                ...               ...   ...   \n",
       "1863  1864                   Reezy feat. Nimo            Trance  2020   \n",
       "1864  1865                           Loredana          Gangster  2020   \n",
       "1865  1866                          Lil Nas X           Holiday  2020   \n",
       "1866  1867                     Studio Killers             Jenny  2020   \n",
       "1867  1868                      Michael Bublé   White Christmas  2020   \n",
       "\n",
       "                                                 lyrics lang  \\\n",
       "0     Fass' dich an, frag', „Ist die Brust da echt?“...   de   \n",
       "1     Ouh-oh-oh-ouh-ouh\\nBaby, ich weiß, was du will...   de   \n",
       "2     Jajajaja\\nOhh, kippe Bombay\\nJaja, jaja, ohh\\n...   de   \n",
       "3     The second someone mentioned you were all alon...   en   \n",
       "4     If I hit it one time, I'ma pipe her\\nIf I hit ...   en   \n",
       "...                                                 ...  ...   \n",
       "1863  Ich wart' seit Tagen auf dich, bis du wieder k...   de   \n",
       "1864  Miksu\\nMacloud\\n\\nDu sagst, du bist ein Gangst...   de   \n",
       "1865  T-T-Tay Keith, Took it to ten (Hey)\\n\\nAyy, it...   en   \n",
       "1866  Jenny, darling, you're my best friend\\nBut the...   en   \n",
       "1867  I'm dreaming of a white Christmas\\nJust like t...   en   \n",
       "\n",
       "                                                  words  \n",
       "0     [fass, frag, brust, echt, tanz, schubst, grund...  \n",
       "1     [ouhohohouhouh, baby, weiß, willst, weißt, kom...  \n",
       "2     [jajajaja, ohh, kippe, bombay, jaja, jaja, ohh...  \n",
       "3     [second, someone, mentioned, alone, could, fee...  \n",
       "4     [hit, one, time, ima, pipe, hit, two, times, l...  \n",
       "...                                                 ...  \n",
       "1863  [yeah, hes, heaven, oh, yeah, youre, lying, ma...  \n",
       "1864  [stahlharter, gladiator, baller, paar, bars, m...  \n",
       "1865  [entstanden, unendlich, langer, zeit, wunder, ...  \n",
       "1866  [heavy, sso, shit, loyalty, royalty, yall, nig...  \n",
       "1867  [yeah, ah, kennst, einn, traum, hast, draußen,...  \n",
       "\n",
       "[1835 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('leave', 13),\n",
       " ('light', 13),\n",
       " ('youve', 6),\n",
       " ('feel', 5),\n",
       " ('lost', 5),\n",
       " ('way', 5),\n",
       " ('place', 4),\n",
       " ('youll', 4),\n",
       " ('grace', 4),\n",
       " ('dont', 3),\n",
       " ('look', 3),\n",
       " ('distance', 3),\n",
       " ('theres', 3),\n",
       " ('house', 3),\n",
       " ('upon', 3),\n",
       " ('hill', 3),\n",
       " ('guidin', 3),\n",
       " ('like', 3),\n",
       " ('lighthouse', 3),\n",
       " ('safe', 3)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count freq of words in the text \n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "fdistlyrics1 = FreqDist(lyrics['words'][3])\n",
    "fdistlyrics1.most_common(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview = pd.read_pickle(\"../../files/pickle/overview.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview = overview[['id', 'month', 'week']]\n",
    "lyricsstrict = pd.merge(lyrics, overview, how='left', on=['id'],\n",
    "                         sort=False)\n",
    "lyricsstrict = lyricsstrict[(lyricsstrict['year'] > 2018) & (lyricsstrict['month'] < 12)]\n",
    "lyricsstrict = lyricsstrict.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "artist    0\n",
       "title     0\n",
       "year      0\n",
       "lyrics    0\n",
       "lang      0\n",
       "words     0\n",
       "month     0\n",
       "week      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyricsstrict.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1158, 9)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyricsstrict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyricsstrict = lyricsstrict.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1158/1158 [00:05<00:00, 230.93it/s]\n"
     ]
    }
   ],
   "source": [
    "#list used to store the information\n",
    "set_words = []\n",
    "set_times = []\n",
    "set_lang = []\n",
    "\n",
    "#Iterate trought each word and decade and stores them into the new lists\n",
    "for i in tqdm(lyricsstrict.index):\n",
    "    for word in lyricsstrict['words'].iloc[i]:\n",
    "        set_words.append(word)\n",
    "        set_times.append(lyricsstrict['year'].iloc[i])\n",
    "        set_lang.append(lyricsstrict['lang'].iloc[i])\n",
    "\n",
    "#create the new data frame  with the information of words and decade lists \n",
    "words_df = pd.DataFrame({'words':set_words,'time':set_times, 'lang': set_lang})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_de = words_df[(words_df['lang'] == 'de')]\n",
    "words_de = words_de[['words', 'time']]\n",
    "words_en = words_df[(words_df['lang'] == 'en')]\n",
    "words_en = words_en[['words', 'time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 39.4 GiB for an array with shape (27172, 194570) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-be6ff068ca8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtext_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords_de\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'words'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdata_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdata_cv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwords_de\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#created a dataframe that Sums the ocurrence frequency of each word and group the result by decade\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2937\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2938\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2940\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2999\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3000\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3001\u001b[1;33m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3002\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3003\u001b[0m         \u001b[1;31m# check if we are modifying a copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3623\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3624\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3625\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mset\u001b[1;34m(self, item, value)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m                     \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblk_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mdelete\u001b[1;34m(self, loc)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[0mDelete\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mblock\u001b[0m \u001b[1;32min\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mplace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \"\"\"\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdelete\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mdelete\u001b[1;34m(arr, obj, axis)\u001b[0m\n\u001b[0;32m   4415\u001b[0m         \u001b[0mkeep\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4416\u001b[0m         \u001b[0mslobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4417\u001b[1;33m         \u001b[0mnew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4419\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 39.4 GiB for an array with shape (27172, 194570) and data type int64"
     ]
    }
   ],
   "source": [
    "# count the frequency of each word that don't have on the stop_words lists          \n",
    "cv = CountVectorizer()\n",
    "\n",
    "#Create a dataframe called data_cv to store the the number of times the word was used in  a lyric based their decades\n",
    "text_cv = cv.fit_transform(words_de['words'].iloc[:])\n",
    "data_cv = pd.DataFrame(text_cv.toarray(),columns=cv.get_feature_names())\n",
    "data_cv['time'] = words_de['time']\n",
    "\n",
    "#created a dataframe that Sums the ocurrence frequency of each word and group the result by decade\n",
    "vect_words = data_cv.groupby('time').sum().T\n",
    "vect_words = vect_words.reset_index(level=0).rename(columns ={'index':'words'})\n",
    "vect_words = vect_words.rename_axis(columns='')\n",
    "\n",
    "#Save the data into a csv file\n",
    "vect_words.to_csv('words.csv',index=False)\n",
    "\n",
    "#change the order of columns to order from the oldest to actual decade\n",
    "vect_words = vect_words[['words','2019', '2020']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics.to_csv(\"../../files/csv/lyricstokenized.csv\")\n",
    "lyrics.to_pickle(\"../../files/pickle/lyricstokenized.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
