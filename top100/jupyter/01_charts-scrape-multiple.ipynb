{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import datetime\n",
    "\n",
    "from time import sleep\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the Top 100 German Charts from the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This script scrapes the following features from the website [www.offiziellecharts.de](www.offiziellecharts.de) for the weeks starting January 5, 2018 until today and saves it as CSV and Pickle:\n",
    "    * current_rank: Current position in the charts\n",
    "    * artist: Name of artist\n",
    "    * title: Title of song\n",
    "    * label: Name of label of the artist\n",
    "    * in_charts: Number of weeks in the charts as of the respective week\n",
    "    * peak: Peak position in the charts over all weeks in the charts recorded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.offiziellecharts.de/charts/single/for-date-1515106800000\"\n",
    "\n",
    "cw = 0\n",
    "y = 2018\n",
    "\n",
    "while True:\n",
    "    rank_current = []\n",
    "    artist = []\n",
    "    title = []\n",
    "    label = []\n",
    "    incharts = []\n",
    "    peak = []\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.content.decode('utf-8', 'ignore'), \"html5lib\")\n",
    "    \n",
    "    #finding out the start and end date of the top 100 songs list\n",
    "    periodhelp = soup.find_all('strong')\n",
    "    \n",
    "    weekdates = []\n",
    "    for dt in periodhelp:\n",
    "        weekdates.append(dt.text)\n",
    "    \n",
    "    if int(datetime.datetime.strptime(weekdates[0], \"%d.%m.%Y\").year) == 2021:\n",
    "        break\n",
    "    \n",
    "    #getting list of current rank   \n",
    "    rankc_help = soup.find_all('span', {'class' : 'this-week'})\n",
    "    rank_current = [int(r.text) for r in rankc_help]\n",
    "    \n",
    "    #getting list of artists\n",
    "    artist_help = soup.find_all('span', {'class' : 'info-artist'})\n",
    "    artist = [r.text for r in artist_help]\n",
    "    \n",
    "    #getting list of titles\n",
    "    title_help = soup.find_all('span', {'class' : 'info-title'})\n",
    "    title = [r.text for r in title_help]\n",
    "    \n",
    "    #getting list of labels\n",
    "    label_help = soup.find_all('span', {'class' : 'info-label'})\n",
    "    label = [r.text for r in label_help]\n",
    "    \n",
    "    #getting list of in charts information\n",
    "    \n",
    "    incharts_help = soup.find_all('span', {'class' : 'plus-data'})\n",
    "    incharts = [r.text.split()[2] for r in incharts_help if len(r.text.split()) > 2]\n",
    "    \n",
    "    #getting list of overall peak position information\n",
    "    peak_help = soup.find_all('span', {'class' : 'plus-data'})\n",
    "    peak = [r.text.split()[1] for r in peak_help if len(r.text.split()) < 3]\n",
    "    \n",
    "    dict_help = {'current_rank': rank_current,\n",
    "                 'artist': artist,\n",
    "                 'title': title,\n",
    "                 'label': label,\n",
    "                 'in_charts': incharts,\n",
    "                 'peak': peak,\n",
    "                }\n",
    "    \n",
    "    df = pd.DataFrame(dict_help)\n",
    "    df['weekbegin'] = datetime.datetime.strptime(weekdates[0], \"%d.%m.%Y\")\n",
    "    df['weekend'] = datetime.datetime.strptime(weekdates[1], \"%d.%m.%Y\")\n",
    "    df['year'] = datetime.datetime.strptime(weekdates[0], \"%d.%m.%Y\").year\n",
    "    df['month'] = datetime.datetime.strptime(weekdates[0], \"%d.%m.%Y\").month\n",
    "    \n",
    "    if int(datetime.datetime.strptime(weekdates[0], \"%d.%m.%Y\").year) == y:\n",
    "        cw += 1\n",
    "        savename_pickle = \"../pickle/chartlists/charts_\" + str(y) + \"_\" + str(cw) + \".pkl\"\n",
    "        savename_csv = \"../csv/charts_\" + str(y) + \"_\" + str(cw) + \".csv\"\n",
    "        df.to_pickle(savename_pickle)\n",
    "        df.to_csv(savename_csv, index=False)\n",
    "        \n",
    "    elif int(datetime.datetime.strptime(weekdates[0], \"%d.%m.%Y\").year) > y:\n",
    "        y = int(datetime.datetime.strptime(weekdates[0], \"%d.%m.%Y\").year)\n",
    "        cw = 1\n",
    "        savename_pickle = \"../pickle/chartlists/charts_\" + str(y) + \"_\" + str(cw) + \".pkl\"\n",
    "        savename_csv = \"../csv/charts_\" + str(y) + \"_\" + str(cw) + \".csv\"\n",
    "        df.to_pickle(savename_pickle)\n",
    "        df.to_csv(savename_csv, index=False)\n",
    "    \n",
    "    if len(soup.find_all('a', {'class' : 'next-link btn btn-default btn-sm'})) > 0:\n",
    "        url = \"https://www.offiziellecharts.de\" + str([a['href'] for a in soup.find_all('a', {'class' : 'next-link btn btn-default btn-sm'})][0]) + \"/\"\n",
    "        #Nap time!\n",
    "        wait_time = randint(1,5)\n",
    "        sleep(wait_time)\n",
    "        continue\n",
    "    \n",
    "    elif (len(soup.find_all('a', {'class' : 'next-link btn btn-default btn-sm'})) <= 0):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
